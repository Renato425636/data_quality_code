# Framework Gen√©rico de Qualidade de Dados com PySpark

Este reposit√≥rio cont√©m um framework de qualidade de dados (DQ) robusto, gen√©rico e configur√°vel, constru√≠do em Python e PySpark. Ele foi projetado para ser uma ferramenta pr√°tica e poderosa para validar a integridade e a consist√™ncia de datasets em um Data Lake ou em qualquer etapa de um pipeline de ETL/ELT.

O grande diferencial deste projeto √© que ele √© **totalmente autocontido**: o √∫nico script Python √© respons√°vel por criar seus pr√≥prios dados de exemplo e arquivos de configura√ß√£o, tornando a demonstra√ß√£o e o teste extremamente simples.

## üèõÔ∏è Vis√£o e Filosofia do Projeto

A confian√ßa nos dados √© o alicerce de qualquer iniciativa de Business Intelligence, Analytics ou Machine Learning. Este framework foi criado para ser um "port√£o de qualidade" automatizado, garantindo que apenas dados que atendam a crit√©rios de neg√≥cio predefinidos prossigam no pipeline.

A filosofia central do projeto √© a **separa√ß√£o entre a l√≥gica de valida√ß√£o e as regras de neg√≥cio**:

  * **A L√≥gica (O "Como"):** A classe `AdvancedDataQualityFramework` cont√©m o motor de valida√ß√£o gen√©rico, escrito em PySpark.
  * **As Regras (O "O Qu√™"):** As valida√ß√µes s√£o definidas externamente em um arquivo `rules.json`, permitindo que a equipe de dados defina e modifique regras sem tocar no c√≥digo do framework.

## ‚ú® Principais Funcionalidades

O framework √© equipado com funcionalidades avan√ßadas para lidar com cen√°rios complexos de qualidade de dados:

‚úîÔ∏è **Motor de Regras via JSON**
Toda a valida√ß√£o √© controlada por um arquivo `rules.json`. Voc√™ pode especificar m√∫ltiplos datasets, e para cada um, uma lista de regras a serem aplicadas em colunas espec√≠ficas.

üö¶ **N√≠veis de Severidade e Controle de Pipeline**
Cada regra pode ter uma a√ß√£o `on_fail` para controle granular do fluxo do pipeline:

  * `"WARN"` (Padr√£o): Registra a falha, mas permite que o pipeline continue. Ideal para problemas de baixa prioridade.
  * `"STOP"`: Interrompe a execu√ß√£o do pipeline **imediatamente** ao encontrar uma falha, lan√ßando uma exce√ß√£o. Essencial para erros cr√≠ticos que invalidam o dataset.

üî¨ **Quarentena de Dados (Isolamento de Erros)**
Quando uma regra falha, o framework pode **isolar os registros exatos** que violaram a regra e salv√°-los em um diret√≥rio de "quarentena". Isso permite uma an√°lise offline detalhada da causa raiz do problema. A funcionalidade √© ativada com o par√¢metro `"quarantine": true`.

üìã **Conjunto Abrangente de Regras de Valida√ß√£o**
O framework j√° vem com um conjunto de regras prontas para uso:

  * **N√≠vel de Linha:** `is_unique`, `is_not_null`, `has_accepted_values`, `is_in_range`, `matches_regex`.
  * **N√≠vel de Agrega√ß√£o (Estat√≠stico):** `null_percentage_is_less_than`, `mean_is_between`.

üìÑ **Relat√≥rios Detalhados em JSON**
Ao final de cada execu√ß√£o, um relat√≥rio completo em formato JSON √© gerado. Ele cont√©m um sum√°rio da execu√ß√£o (total de regras, aprovadas, falhas) e os detalhes de cada teste, incluindo as m√©tricas que levaram √† falha.

## üîß Como Funciona: O Arquivo de Regras (`rules.json`)

O cora√ß√£o da customiza√ß√£o do framework √© o arquivo `rules.json`. Ele define quais valida√ß√µes executar.

**Estrutura do `rules.json`:**

```json
{
    "validation_sets": [
        {
            "dataset_name": "Clientes",
            "data_source_path": "data/customers_v2.csv",
            "data_source_format": "csv",
            "rules": [
                {
                    "rule_type": "is_unique",
                    "column": "customer_id",
                    "on_fail": "STOP",
                    "quarantine": true
                },
                {
                    "rule_type": "null_percentage_is_less_than",
                    "column": "state",
                    "params": {
                        "threshold": 15
                    },
                    "on_fail": "WARN"
                },
                {
                    "rule_type": "mean_is_between",
                    "column": "age",
                    "params": {
                        "min": 20,
                        "max": 40
                    }
                }
            ]
        }
    ]
}
```

**Anatomia de uma regra:**

  * `rule_type`: O tipo de valida√ß√£o a ser aplicada (ex: `is_unique`).
  * `column`: A coluna alvo da valida√ß√£o.
  * `params`: (Opcional) Um objeto com par√¢metros espec√≠ficos para a regra (ex: `threshold` para porcentagem de nulos, ou `min` e `max` para um intervalo).
  * `on_fail`: (Opcional, padr√£o "WARN"). Define a a√ß√£o em caso de falha: `"WARN"` para continuar ou `"STOP"` para interromper o pipeline.
  * `quarantine`: (Opcional, padr√£o `false`). Se `true`, os registros que falharem nesta regra ser√£o salvos para an√°lise.

## üöÄ Como Executar o Projeto

Este projeto √© **autocontido**. O √∫nico script Python ir√° gerar automaticamente todos os arquivos necess√°rios para a demonstra√ß√£o.

### 1\. Pr√©-requisitos

  * Python 3.9 ou superior.
  * Java Development Kit (JDK) 8 ou 11 (necess√°rio para o Spark).
  * Instale as depend√™ncias Python:
    ```bash
    pip install pyspark pyyaml
    ```

### 2\. Execu√ß√£o

Basta salvar o c√≥digo fornecido como um arquivo (ex: `dq_framework_standalone.py`) e execut√°-lo a partir do seu terminal:

```bash
python dq_framework_standalone.py
```

**O que acontece durante a execu√ß√£o:**

1.  A fun√ß√£o `setup_test_environment()` √© chamada primeiro.
2.  Ela cria os diret√≥rios `data/`, `reports/` e `quarantine/`.
3.  Ela cria os arquivos `config.yaml`, `rules.json` e `data/customers_v2.csv`.
4.  S√≥ ent√£o o `AdvancedDataQualityFramework` √© iniciado, lendo os arquivos que acabaram de ser criados.

### 3\. Entendendo a Sa√≠da

Ap√≥s a execu√ß√£o, voc√™ ver√°:

  * **No Console:** Logs detalhados de cada regra sendo executada. A execu√ß√£o ser√° **interrompida** com uma mensagem de erro cr√≠tico, pois a regra `is_unique` para `customer_id` ir√° falhar (conforme definido com `"on_fail": "STOP"`).
  * **Diret√≥rio `reports/`:** Conter√° um arquivo `dq_report_...json` com o relat√≥rio detalhado das regras que foram executadas at√© a interrup√ß√£o.
  * **Diret√≥rio `quarantine/`:** Conter√° um subdiret√≥rio `Clientes/is_unique_customer_id/`, e dentro dele, um arquivo Parquet com os registros de `customer_id = 104` que causaram a falha, prontos para sua an√°lise.
